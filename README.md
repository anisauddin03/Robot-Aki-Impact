As part of my module Inovation Project CMP4285 at Birmingham City University, my team have developed a robot that is able to respond to user emotions. This is the 1st place project that has won this year (2024) during the Awards Ceremony. Two main features of the robot are:
- To produce a display image on the LCD screen and sound output via speaker whenever it detects user's emotion through facial recognition
- Placing user's hand above the ultrasonic sensor will prompt the arms of the robot to move at right angles (almost as if user is petting the head of the robot, robot waves its arms in happiness)

The robot consist of Raspberry Pi and Arduino. The files uploaded onto this repositories are from the Raspberry Pi. I have also included a video of how the robot operates in real time (this can be viewed on the Robot Aki in motion.mp4) and also an image of the Robot Aki connected together and placed inside the 3D printed parts.

The code for emotional detection and recognition was modified from this repository:
https://github.com/jamarma/emotion_detection_ros.git

I hope this repository helps other programmers out there that would also like to use emotional detection or provide an insight on how to develop the robot.

Thank you for reading!
